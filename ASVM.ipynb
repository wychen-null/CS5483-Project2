{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 7972058,
     "sourceType": "datasetVersion",
     "datasetId": 4690782
    },
    {
     "sourceId": 8113636,
     "sourceType": "datasetVersion",
     "datasetId": 4793249
    }
   ],
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "text": "Collecting utils\n  Downloading utils-1.0.2.tar.gz (13 kB)\n  Preparing metadata (setup.py) ... \u001B[?25ldone\n\u001B[?25hBuilding wheels for collected packages: utils\n  Building wheel for utils (setup.py) ... \u001B[?25ldone\n\u001B[?25h  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13905 sha256=4def10c3a683fa949d66308b47a2c0fe8b7c2e099a3ee5b15f9fd0e7aeea25f2\n  Stored in directory: /root/.cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\nSuccessfully built utils\nInstalling collected packages: utils\nSuccessfully installed utils-1.0.2\n",
     "output_type": "stream"
    }
   ],
   "source": [
    "! pip install utils"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def train_test_split(x, y):\n",
    "    trainX, testX, trainY, testY = \\\n",
    "        model_selection.train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=4487)\n",
    "    return trainX, trainY, testX, testY\n",
    "\n",
    "\n",
    "def plot_roc(validY, validProb):\n",
    "    # ROC AUC\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(validY, validProb, pos_label=1)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print(\"ROC_AUC :\", roc_auc)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('#e8e8f8')\n",
    "    plt.plot(fpr, tpr, 'k-', lw=2, color='#7777cb')\n",
    "    plt.title('AUC={:.4f}'.format(roc_auc))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.gca().set_facecolor('#e8e8f8')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:17:53.322210Z",
     "iopub.execute_input": "2024-04-19T16:17:53.322630Z",
     "iopub.status.idle": "2024-04-19T16:17:53.332955Z",
     "shell.execute_reply.started": "2024-04-19T16:17:53.322599Z",
     "shell.execute_reply": "2024-04-19T16:17:53.331669Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from utils import *\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "random.seed(4487)\n",
    "with open('/kaggle/input/dm-pkl/data.pkl', 'rb') as file:\n",
    "    # 使用pickle的load方法从文件反序列化数据\n",
    "        data_loaded = pickle.load(file)\n",
    "# data_loaded现在是一个包含x，y，label的字典\n",
    "x = data_loaded['x']\n",
    "y = data_loaded['y']\n",
    "label = data_loaded['label']\n",
    "trainX, testX, trainY, testY = train_test_split(x, y)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:17:56.340061Z",
     "iopub.execute_input": "2024-04-19T16:17:56.340480Z",
     "iopub.status.idle": "2024-04-19T16:17:57.529022Z",
     "shell.execute_reply.started": "2024-04-19T16:17:56.340445Z",
     "shell.execute_reply": "2024-04-19T16:17:57.527750Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# ASVM detail"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import numpy\n",
    "\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "from pandas import *\n",
    "from scipy import stats"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:10.433655Z",
     "iopub.execute_input": "2024-04-19T16:19:10.434046Z",
     "iopub.status.idle": "2024-04-19T16:19:10.893836Z",
     "shell.execute_reply.started": "2024-04-19T16:19:10.434018Z",
     "shell.execute_reply": "2024-04-19T16:19:10.892763Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 原始SVAM的重复性过程抽出定义为函数"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,C,gamma=False,degree=False,coef0=False):\n",
    "    if C < 0:\n",
    "        C = random.randint(1,5) \n",
    "    clf = svm.SVC(C=C, kernel=kernel,gamma=gamma, coef0=coef0, probability=True,random_state=920).fit(x_traincv, y_traincv)\n",
    "    y_score = clf.predict_proba(x_testcv)[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_testcv, y_score, pos_label=1)\n",
    "    roc_auc = metrics.auc(fpr,tpr)\n",
    "    \n",
    "    return roc_auc "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:13.183725Z",
     "iopub.execute_input": "2024-04-19T16:19:13.184096Z",
     "iopub.status.idle": "2024-04-19T16:19:13.191984Z",
     "shell.execute_reply.started": "2024-04-19T16:19:13.184068Z",
     "shell.execute_reply": "2024-04-19T16:19:13.190936Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(- 0.0002/log(0.01))#最小温度\n",
    "print(- 0.0002/log(0.4))#最大温度\n",
    "#这里改一下\n",
    "print((0.0002182713335874583/0.00004342944819032519)**(1/10))  \n",
    "a = 0.0004342944819032519\n",
    "for i in range(10):\n",
    "    a*=1.175\n",
    "print(a)\n",
    "print(e**(-0.0001/0.00021785271532936534))\n",
    "print(random.randint(1,10))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:14.620845Z",
     "iopub.execute_input": "2024-04-19T16:19:14.621263Z",
     "iopub.status.idle": "2024-04-19T16:19:14.629265Z",
     "shell.execute_reply.started": "2024-04-19T16:19:14.621229Z",
     "shell.execute_reply": "2024-04-19T16:19:14.627825Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "4.342944819032519e-05\n0.00021827133358745833\n1.1752255889451046\n0.0021785271532936534\n0.6318989908213715\n7\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def SFLA_SVM_CV(x_train, y_train,n,kernel,C,gamma=False,degree=False,coef0=False):\n",
    "    '''\n",
    "    n: number of splits for k-fold\n",
    "    \n",
    "    '''\n",
    "    KF = KFold(n_splits=n,shuffle=True, random_state=920)\n",
    "    f = []\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        fq = SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,C,gamma=gamma,degree=degree,coef0=coef0) \n",
    "        f.append(fq) \n",
    "    f = mean(f)\n",
    "    return f"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:16.043168Z",
     "iopub.execute_input": "2024-04-19T16:19:16.043601Z",
     "iopub.status.idle": "2024-04-19T16:19:16.052239Z",
     "shell.execute_reply.started": "2024-04-19T16:19:16.043569Z",
     "shell.execute_reply": "2024-04-19T16:19:16.050992Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "    # 检查青蛙是否在可行的搜索空间内\n",
    "    return (rangeC[0] <= Uq[0] <= rangeC[1]) and \\\n",
    "           (rangeGamma[0] <= Uq[1] <= rangeGamma[1]) and \\\n",
    "           (rangeCoef0[0] <= Uq[2] <= rangeCoef0[1])and \\\n",
    "           (Uq[0] >= 0) and \\\n",
    "           (Uq[1] >= 0) and \\\n",
    "           (Uq[2] >= 0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:17.542664Z",
     "iopub.execute_input": "2024-04-19T16:19:17.543039Z",
     "iopub.status.idle": "2024-04-19T16:19:17.551188Z",
     "shell.execute_reply.started": "2024-04-19T16:19:17.543011Z",
     "shell.execute_reply": "2024-04-19T16:19:17.548803Z"
    },
    "trusted": true
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_random_frog(rangeC, rangeGamma, rangeCoef0):\n",
    "    \"\"\"\n",
    "    Randomly generates a new frog within the feasible space.\n",
    "    \n",
    "    Parameters:\n",
    "    - rangeC: Tuple (min, max) for C parameter.\n",
    "    - rangeGamma: Tuple (min, max) for Gamma parameter.\n",
    "    - rangeCoef0: Tuple (min, max) for Coef0 parameter.\n",
    "    \n",
    "    Returns:\n",
    "    - Uq: A list containing the randomly generated C, Gamma, and Coef0.\n",
    "    \"\"\"\n",
    "    Uq = [\n",
    "        10**random.uniform(log10(rangeC[0]), log10(rangeC[1])),\n",
    "        10**random.uniform(log10(rangeGamma[0]), log10(rangeGamma[1])),\n",
    "        random.uniform(rangeCoef0[0], rangeCoef0[1])\n",
    "    ]\n",
    "    return Uq\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:18.969320Z",
     "iopub.execute_input": "2024-04-19T16:19:18.969985Z",
     "iopub.status.idle": "2024-04-19T16:19:18.977126Z",
     "shell.execute_reply.started": "2024-04-19T16:19:18.969950Z",
     "shell.execute_reply": "2024-04-19T16:19:18.975942Z"
    },
    "trusted": true
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations):\n",
    "    # 计算适应性因子，随着迭代进行，减小探索的随机性，alpha将更趋近于1，按本文的数据，最终alpha等于(1/e)\n",
    "    alpha = exp(-iteration / max_iterations)\n",
    "    # 用高斯分布代替均匀分布来生成随机数\n",
    "    gauss_factor = random.normal(1, 0.3)  # 均值1，标准差0.35\n",
    "    # 应用高斯扰动和适应性因子\n",
    "    Uq = Pw[1:] + alpha * gauss_factor * (frog_gb - Pw[1:])\n",
    "    return Uq"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:21.338673Z",
     "iopub.execute_input": "2024-04-19T16:19:21.339083Z",
     "iopub.status.idle": "2024-04-19T16:19:21.347881Z",
     "shell.execute_reply.started": "2024-04-19T16:19:21.339051Z",
     "shell.execute_reply": "2024-04-19T16:19:21.346516Z"
    },
    "trusted": true
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 模拟退火算法改进最坏青蛙后的ASVM"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def SFLA_SIGMOID(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0,performance_history00,x_train,y_train):\n",
    "    '''\n",
    "    num_parameter: int, number of parameter to optimize\n",
    "    \n",
    "    num_global: int, the maximum number of global iterations\n",
    "    \n",
    "    num_local: int, the maximum number of local iterations\n",
    "    \n",
    "    m : int, the number of memeplexes\n",
    "    \n",
    "    n : int, the number of frogs in each memeplex\n",
    "    \n",
    "    q : int, the number of frogs in submemeplex\n",
    "    \n",
    "    n1:  number of splits for cross validation for inner loop\n",
    "    \n",
    "    rangeC: list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "    \n",
    "    rangeGamma: list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "    \n",
    "    rangeCoef0: list, float, range of parameter Coef0,eg.[0, 1]\n",
    "\n",
    "    x_train: feature\n",
    "\n",
    "    y_train: lable\n",
    "\n",
    "    '''\n",
    "\n",
    "    #--- Step 0--Initialize parameters ---#\n",
    "    sizeC = 2\n",
    "    sizeGamma = 2\n",
    "    sizeCoef0 = 2\n",
    "    improvement_threshold = 10**-4 # 设置一个性能改进的阈值\n",
    "    performance_history = performance_history00 # 用于存储每只青蛙的历史性能和权重\n",
    "    global_flags = False\n",
    "    stop_main_loop = False\n",
    "    # max_step =  [(rangeC[1]-rangeC[0])/sizeC,(rangeGamma[1]-rangeGamma[0])/sizeGamma,(rangeCoef0[1]-rangeCoef0[0])/sizeCoef0]# maximum step size\n",
    "    initial_max_step =  [(rangeC[1]-rangeC[0])/sizeC,(rangeGamma[1]-rangeGamma[0])/sizeGamma,(rangeCoef0[1]-rangeCoef0[0])/sizeCoef0]# maximum step size\n",
    "    #--- Step 1--Generate initial population ---#\n",
    "    frogC = 10**random.uniform(log10(rangeC[0]),log10(rangeC[1]),m*n)\n",
    "    frogGamma = 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1]),m*n)\n",
    "    frogCoef0 = random.uniform(rangeCoef0[0],rangeCoef0[1],m*n)\n",
    "    frog = c_[frogC,frogGamma,frogCoef0]\n",
    "\n",
    "    # Compute the performance value for each frog on validation data #\n",
    "    KF = KFold(n_splits=n1,shuffle=True, random_state=920)\n",
    "    f = zeros((m*n,n1))\n",
    "    j = 0\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        for i in range(m*n):\n",
    "            f[i,j] = SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,frog[i,0],frog[i,1],frog[i,2])\n",
    "        j+=1\n",
    "    f = f.mean(axis=1)\n",
    "    f_parameter = c_[f,frog]\n",
    "\n",
    "    #--- Step 2--Rank frogs ---#\n",
    "    f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "    #######--- Global search start---######\n",
    "    i_global = 0\n",
    "    flag = 0\n",
    "    fBest_iteration = f_parameter[0,0]\n",
    "    weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "    while i_global < num_global:\n",
    "        # Dynamically adjust the maximum step size based on the iteration number\n",
    "        decay_factor = 0.89  # This factor determines how much the step size is reduced\n",
    "        max_step = [x * (decay_factor ** i_global) for x in initial_max_step]\n",
    "        frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "        #--- Step 3--Partition frogs into memeplexes ---#\n",
    "        memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma,Coef0] ]\n",
    "        for i in range(m):\n",
    "            memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "\n",
    "       #######--- Global search start---######\n",
    "        i_global = 0\n",
    "        flag = 0\n",
    "        fBest_iteration = f_parameter[0,0]\n",
    "        iteration = 1              # 当前迭代次数高斯\n",
    "        max_iterations = 10        # 最大迭代次数高斯\n",
    "        iteration_sa = 1\n",
    "        \n",
    "        # 初始化温度参数\n",
    "        initial_temp = 0.00004342944819032519\n",
    "        cooling_rate = 1.175  # 温度增长率\n",
    "        T = initial_temp  # 当前温度\n",
    "        global_flags = False\n",
    "        stop_main_loop = False\n",
    "        markf = 0\n",
    "        weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "        while i_global < num_global:\n",
    "            # Dynamically adjust the maximum step size based on the iteration number\n",
    "            decay_factor = 0.89  # This factor determines how much the step size is reduced\n",
    "            max_step = [x * (decay_factor ** i_global) for x in initial_max_step]\n",
    "            frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "            # Step 3: Partition frogs into memeplexes\n",
    "            memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma,Coef0] ]\n",
    "            for i in range(m):\n",
    "                memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "            #######--- Local search start---######\n",
    "            # Step 4: Memetic evolution within each memeplex\n",
    "            im = 0 # the number of memeplexes that have been optimized\n",
    "            global_flags = False\n",
    "            stop_main_loop = False\n",
    "            markf = 0 # 这个就是标记是否在子复合体中找到了有效改进解，如果这个标记是1，说明没有找到\n",
    "            while im < m:\n",
    "                global_flags = False\n",
    "                stop_main_loop = False\n",
    "                i_local = 0 # counts the number of local evolutionary steps in each memeplex\n",
    "                while i_local < num_local:\n",
    "                    # Construct a submemeplex\n",
    "                    memeplex_indices = range(im * n, (im + 1) * n)\n",
    "                    if not all(performance_history[memeplex_indices, 1] == 0):\n",
    "                        rValue = random.random(q)\n",
    "                        memeplex_weights = performance_history[memeplex_indices, 1]\n",
    "                        random_indices = random.choice(memeplex_indices, size=q, p=memeplex_weights/sum(memeplex_weights), replace=False)\n",
    "                        selected_weights = performance_history[random_indices, 1]\n",
    "                        rValue *= selected_weights\n",
    "                        subindex = sort(argsort(rValue)[::-1][0:q])\n",
    "                    else:\n",
    "                        rValue = random.random(n)*weights \n",
    "                        subindex = sort(argsort(rValue)[::-1][0:q]) # index of selected frogs in memeplex \n",
    "                    submemeplex = memeplexes[im][subindex] # form submemeplex\n",
    "                    # Improve the worst frog's position using Simulated Annealing\n",
    "                    Pb = submemeplex[0]  # mark the best frog in submemeplex\n",
    "                    Pw = submemeplex[q-1]  # mark the worst frog in memeplex\n",
    "                    S = (Pb - Pw)[1:] * (Pb - Pw)[0]\n",
    "                    Uq = Pw[1:] + S\n",
    "                    # Check feasible space and the performance\n",
    "                    if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                        fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                        if fq < Pw[0]:\n",
    "                            # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                            # 改进为使用结合模拟退火算法的高斯插值方法混合当前青蛙和全局最佳青蛙的参数，而不是完全随机生成\n",
    "                            # 注意这里退火算法我改了，评价指标改成一个单增的函数，就表示如果最坏青蛙向最好青蛙学习之后，如果性能下降了，但下降的越少的学习结果越容易被接受\n",
    "                            while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                                    fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                                    if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                        while iteration_sa < max_iterations + 1:\n",
    "                                            if random.rand() > exp(-(Pw[0] - fq) / T):#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右,\n",
    "                                                #如果相差在0.0015，那么最大接受概率约为0.5023096165445047，0.1~0.6318989908213715，这里就是为了带来随机性，增加鲁棒性\n",
    "                                                T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                iteration_sa += 1\n",
    "                                            else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                top_main_loop = True\n",
    "                                                global_flags = True\n",
    "                                                iteration_sa = 1\n",
    "                                                break\n",
    "                                        T = initial_temp #记得再次初始化T，不然T乘直接乘爆炸了\n",
    "                                        iteration_sa = 1\n",
    "                                iteration += 1\n",
    "                            if iteration == max_iterations + 1:\n",
    "                                markf = 1 #这就说明上面的没有找到局部改进解\n",
    "                            stop_main_loop = False    \n",
    "                            iteration = 1\n",
    "                        elif markf == 1: # if local parameter has not been improved then we go global for searching\n",
    "                            markf = 0\n",
    "                             # if searching has no result.get a new direction from the global best frog randomly\n",
    "                            S = random.random(num_parameter) * (frog_gb - Pw)[1:]\n",
    "                            for i in range(num_parameter):\n",
    "                                if S[i] > 0:\n",
    "                                    S[i] = min(S[i], max_step[i])\n",
    "                                else:\n",
    "                                    S[i] = min(S[i], -max_step[i])\n",
    "                            Uq = Pw[1:] + S\n",
    "                            if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                                if fq < Pw[0]:\n",
    "                                # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                                    while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                        Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                        if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                                            if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                                while iteration_sa < max_iterations + 1:\n",
    "                                                    if random.rand() > exp(-(Pw[0] - fq) / T) :#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右\n",
    "                                                        T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                        iteration_sa += 1\n",
    "                                                    else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                        top_main_loop = True\n",
    "                                                        global_flags = True\n",
    "                                                        iteration_sa = 1\n",
    "                                                        break\n",
    "                                                T = initial_temp #记得再次初始化T\n",
    "                                                iteration_sa = 1\n",
    "                                        iteration += 1\n",
    "                                    stop_main_loop = False\n",
    "                                    iteration = 1\n",
    "                            else:# 注意这里还是在前提，是在局部学习和全局学习都没有提升的前提下，这里还有一个前提是在局部学习是在可行界内的\n",
    "                                # If both local and global 's performances are not improved and new solution is not accepted based on annealing probability\n",
    "                                # Randomly generate a legal frog within the submemeplex\n",
    "                                Uq = generate_random_frog(rangeC, rangeGamma, rangeCoef0)\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                    else: # 如果局部学习直接不在可行解内了\n",
    "                        # If the worst frog 1 is beyond the search space, get a new direction from the global best frog for search\n",
    "                        S = random.random(num_parameter) * (frog_gb - Pw)[1:]\n",
    "                        for i in range(num_parameter):\n",
    "                            if S[i] > 0:\n",
    "                                S[i] = min(S[i], max_step[i])\n",
    "                            else:\n",
    "                                S[i] = min(S[i], -max_step[i])\n",
    "                        Uq = Pw[1:] + S\n",
    "                        if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                            if fq < Pw[0]:\n",
    "                            # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                                while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                    Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                    if check_within_bounds(Uq, rangeC, rangeGamma, rangeCoef0):\n",
    "                                        fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                                        if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                            while iteration_sa < max_iterations + 1:\n",
    "                                                if random.rand() > exp(-(Pw[0] - fq) / T) :#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右\n",
    "                                                    T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                    iteration_sa += 1\n",
    "                                                else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                    top_main_loop = True\n",
    "                                                    global_flags = True\n",
    "                                                    iteration_sa = 1\n",
    "                                                    break\n",
    "                                            T = initial_temp #记得再次初始化T\n",
    "                                            iteration_sa = 1\n",
    "                                    iteration += 1\n",
    "                                stop_main_loop = False\n",
    "                                iteration = 1\n",
    "                            else:\n",
    "                                # if global learning is not improved Randomly generate a legal frog within the submemeplex\n",
    "                                Uq = generate_random_frog(rangeC, rangeGamma, rangeCoef0)\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "                        # if the space of the global learning is not feasible  Randomly generate a legal frog within the submemeplex\n",
    "                        else:\n",
    "                            Uq = generate_random_frog(rangeC, rangeGamma, rangeCoef0)\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1], Uq[2])\n",
    "#                     # Upgrade the memeplex\n",
    "#                     memeplexes[im][subindex[q-1]] = r_[fq, Uq]\n",
    "#                     memeplexes[im] = memeplexes[im][argsort(memeplexes[im][:,0])[::-1]]\n",
    "                    if fq > Pw[0] : # If there is performance improvement\n",
    "                        memeplexes[im][subindex[q-1]] = r_[fq,Uq]\n",
    "                        # Update the frog's historical performance and weight\n",
    "                        performance_history[subindex[q-1], 0] = fq\n",
    "                        performance_history[subindex[q-1], 1] += improvement_threshold # Increase weight\n",
    "                    elif global_flags == True : # If there is SA ACCECPT which means  the worst frog is closed to the best Within the tolerable performance degradation range\n",
    "                        # Update the frog's historical performance and weight\n",
    "                        performance_history[subindex[q-1], 0] = fq\n",
    "                        performance_history[subindex[q-1], 1] += improvement_threshold # Increase weight\n",
    "                        global_flags = False\n",
    "                    else:\n",
    "                        # If there is no performance improvement,and no SA ACCECPT, reduce the weight\n",
    "                        performance_history[subindex[q-1], 1] = max(performance_history[subindex[q-1], 1] - improvement_threshold, 0.1) # Ensure weight does not become zero\n",
    "                        #  By setting a minimum weight as 0.1, we ensure that every frog still has a chance to be selected, \n",
    "                        # but those with better performance have a higher probability.\n",
    "                    i_local += 1\n",
    "                im += 1\n",
    "            #######--- Local search end---######\n",
    "            # Step 5: Shuffle memeplexes\n",
    "            f_parameter = memeplexes.reshape(m*n,num_parameter+1)\n",
    "            f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "            i_global += 1\n",
    "            # Step 6: Check convergence\n",
    "            if f_parameter[0,0] > 0.99:\n",
    "                print('The program was terminated because it reached the optimization goal with f = %.3f' %f_parameter[0,0])\n",
    "                break\n",
    "            if abs(frog_gb - f_parameter[0,0]) < 10**-4:\n",
    "                flag += 1\n",
    "            if flag > 5:\n",
    "                break\n",
    "            fBest_iteration = r_[fBest_iteration, f_parameter[0,0]]\n",
    "        #######--- Global search end---######\n",
    "        return (f_parameter[0], fBest_iteration)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-18T11:36:14.705664Z",
     "iopub.execute_input": "2024-04-18T11:36:14.706093Z",
     "iopub.status.idle": "2024-04-18T11:36:14.776828Z",
     "shell.execute_reply.started": "2024-04-18T11:36:14.706059Z",
     "shell.execute_reply": "2024-04-18T11:36:14.775566Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 并行K-Fold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix as cm, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def train_and_evaluate(train_index, test_index, x, y, n1, kernel, rangeC, rangeGamma, rangeCoef0, num_parameter, num_global, num_local, m, n, q, performance_history):\n",
    "#     # 选取训练集和测试集\n",
    "#     x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # 处理NaN值\n",
    "#     x_train.fillna(0, inplace=True)\n",
    "#     x_test.fillna(0, inplace=True)\n",
    "    #---  Seperate traing set and test set ---#\n",
    "    y_score = []\n",
    "    y_test = []\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train = y.iloc[train_index][:]\n",
    "        \n",
    "    #---  Fill NaN age ---#\n",
    "    x_train[isnan(x_train)] = 0\n",
    "    x_test[isnan(x_test)] = 0    \n",
    "        \n",
    "    ##---  optimize SVM with SFLA---##\n",
    "    x_train = pd.DataFrame(x_train) \n",
    "    y_train = pd.Series(y_train)\n",
    "    \n",
    "    if kernel == 'poly':\n",
    "        f_parameter,fBest_iteration = SFLA_POLY(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeDegree,rangeCoef0,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],degree=f_parameter[3],coef0=f_parameter[4],probability=True,random_state=920)\n",
    "            \n",
    "        \n",
    "    if kernel == 'rbf':\n",
    "        f_parameter,fBest_iteration = SFLA_RBF(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,performance_history,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],probability=True,random_state=920)\n",
    "        \n",
    "    if kernel == 'linear':\n",
    "        f_parameter,fBest_iteration = SFLA_LINEAR(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,x_train,y_train)\n",
    "         # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        \n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],probability=True,random_state=920)\n",
    "        \n",
    "    if kernel == 'sigmoid':\n",
    "        f_parameter,fBest_iteration = SFLA_SIGMOID(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0,performance_history,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "    \n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],coef0=f_parameter[3],probability=True,random_state=920)\n",
    "\n",
    "    # 输出参数\n",
    "    print(f_parameter)\n",
    "    \n",
    "    # 创建并训练SVM模型\n",
    "    # clf = svm.SVC(kernel=kernel, C=f_parameter[1], gamma=f_parameter[2], coef0=f_parameter[3], probability=True, random_state=920)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # Make predictions\n",
    "    y_score = clf.predict_proba(x_test)[:, 1]\n",
    "    y_test = y.iloc[test_index].tolist()\n",
    "    # Check if y_test and y_score have the same length\n",
    "    if len(y_test) != len(y_score):\n",
    "        raise ValueError(f\"Inconsistent number of samples: y_test has {len(y_test)} elements, y_score has {len(y_score)} elements\")\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC:', roc_auc)\n",
    "    \n",
    "    return y_score, y_test, roc_auc, clf\n",
    "    \n",
    "\n",
    "# 主函数\n",
    "def OptimizeSVM_SFLA_CV(x, y, n_splits, num_parameter, num_global, num_local, m, n, q, n1, kernel, rangeC, rangeGamma=False, rangeDegree=False, rangeCoef0=False):\n",
    "    performance_history = np.zeros((m*n, 2)) + 1.0\n",
    "    KF = KFold(n_splits=n_splits, shuffle=True, random_state=random.randint(1, 1000))\n",
    "    y_score = []\n",
    "    y_test = []\n",
    "    # 使用joblib并行处理\n",
    "    if \n",
    "    results = Parallel(n_jobs=-1, verbose=10)(delayed(train_and_evaluate)(\n",
    "        train_index, test_index, x, y, n1, kernel, rangeC, rangeGamma, rangeCoef0, num_parameter, num_global, num_local, m, n, q, performance_history\n",
    "    ) for train_index, test_index in KF.split(x))\n",
    "\n",
    "    # 合并结果\n",
    "    y_scores = [score for result in results for score in result[0]]\n",
    "    y_tests = [y_test for result in results for y_test in result[1]]\n",
    "    roc_aucs = [result[2] for result in results]\n",
    "    clf = [result[3] for result in results]\n",
    "    \n",
    "\n",
    "    \n",
    "    # 输出整体AUC\n",
    "    fpr, tpr, threshold = roc_curve(y_tests, y_scores, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # print('Overall AUC:', roc_auc)\n",
    "\n",
    "    # 计算其他性能指标\n",
    "    y_pred = [round(score) for score in y_scores]\n",
    "    print(cm(y_tests, y_pred))\n",
    "    a = accuracy_score(y_tests, y_pred)\n",
    "    p = precision_score(y_tests, y_pred)\n",
    "    r = recall_score(y_tests, y_pred)\n",
    "    f1score = f1_score(y_tests, y_pred)\n",
    "    print(f'Accuracy: {a:.2f}\\nPrecision: {p:.2f}\\nRecall: {r:.2f}\\nF1 Score: {f1score:.2f}\\nAUC: {roc_auc:.4f}\\n')\n",
    "\n",
    "    return clf, a, p, r, f1score, roc_auc, y_pred, y_scores, fpr, tpr\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-18T13:33:06.990343Z",
     "iopub.execute_input": "2024-04-18T13:33:06.990785Z",
     "iopub.status.idle": "2024-04-18T13:33:07.019355Z",
     "shell.execute_reply.started": "2024-04-18T13:33:06.990749Z",
     "shell.execute_reply": "2024-04-18T13:33:07.018121Z"
    },
    "trusted": true
   },
   "execution_count": 71,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-18T13:30:37.682647Z",
     "iopub.execute_input": "2024-04-18T13:30:37.683090Z",
     "iopub.status.idle": "2024-04-18T13:30:37.687964Z",
     "shell.execute_reply.started": "2024-04-18T13:30:37.683054Z",
     "shell.execute_reply": "2024-04-18T13:30:37.686927Z"
    },
    "trusted": true
   },
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "x_df = pd.DataFrame(x)\n",
    "y_s = pd.Series(y.ravel())  # 使用 ravel() 确保 y 是一维的\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "n_splits = 10 # 减少外循环的分割数\n",
    "num_parameter = 3\n",
    "num_global = 5 # 减少全局迭代的次数\n",
    "num_local = 5 # 减少局部迭代的次数\n",
    "m = 6 # 减少记忆复合体的数量\n",
    "n = 7 # 减少每个记忆复合体中的青蛙数量\n",
    "q = 4 # 减少子记忆复合体中的青蛙数量\n",
    "n1 = 10 # 减少内循环的分割数\n",
    "kernel = 'sigmoid'\n",
    "rangeC = [0.0001, 1000] # 缩小参数C的范围\n",
    "rangeGamma = [0.00001, 1] # 缩小参数Gamma的范围\n",
    "rangeCoef0 = [0, 1] # 参数Coef0的范围保持不变\n",
    "clf, a, p, r, f1score,roc_auc, y_pred,y_score,fpr, tpr = OptimizeSVM_SFLA_CV(x_df,y_s,n_splits,num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0=rangeCoef0)\n",
    "end = time.process_time()\n",
    "print('OptimizeSVM_SFLA_CV algorithm takes '+str(end - start)+'seconds.\\n') "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-18T08:16:47.230516Z",
     "iopub.execute_input": "2024-04-18T08:16:47.230899Z",
     "iopub.status.idle": "2024-04-18T08:46:43.651043Z",
     "shell.execute_reply.started": "2024-04-18T08:16:47.230870Z",
     "shell.execute_reply": "2024-04-18T08:46:43.649741Z"
    },
    "trusted": true
   },
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 21.3min remaining: 21.3min\n[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed: 22.3min remaining:  9.5min\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[9.37115565e-01 1.81382258e+02 6.27891735e-04 9.79618379e-01]\nAUC: 0.9217391304347826\n[9.30464728e-01 8.85295816e+02 1.76831898e-04 9.36340607e-01]\nAUC: 0.9386363636363636\n[9.35953963e-01 5.41362053e+02 9.58444738e-04 2.52037737e-01]\nAUC: 0.9437229437229437\n[9.30936547e-01 3.49051255e+01 1.94046500e-03 7.99892861e-01]\nAUC: 0.9568181818181819\n[[193  22]\n [ 43 165]]\nAccuracy: 0.85\nPrecision: 0.88\nRecall: 0.79\nF1 Score: 0.84\nAUC: 0.9240\n\nOptimizeSVM_SFLA_CV algorithm takes 8.366644934seconds.\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 29.9min finished\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[9.45322474e-01 1.69233060e+01 1.42351676e-02 7.86000739e-01]\nAUC: 0.8478260869565217\n[9.46843163e-01 4.46094979e+02 9.37301123e-04 6.89696355e-01]\nAUC: 0.8820861678004533\n[9.34859698e-01 4.18273657e+02 3.28334283e-04 5.60445112e-01]\nAUC: 0.9254807692307693\n[0.91969082 0.49313012 0.09844826 0.7423793 ]\nAUC: 0.8379629629629629\n[9.29600928e-01 2.83097239e+02 1.19281688e-04 4.64583931e-01]\nAUC: 0.9433106575963719\n[9.28254883e-01 8.48803595e+02 5.37606778e-04 9.97038146e-01]\nAUC: 0.9580246913580248\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# n_splits = 10 # number of splits for outer loop\n",
    "# num_parameter = 3# number of parameter to optimize\n",
    "# num_global = 30# the maximum number of global iterations\n",
    "# num_local = 20# the maximum number of local iterations\n",
    "# m =4 # the number of memeplexes\n",
    "# n = 8 # the number of frogs in each memeplex\n",
    "# q = 5 # the number of frogs in submemeplex\n",
    "# n1 = 10 # number of splits for inner loop\n",
    "# kernel = 'sigmoid'\n",
    "# rangeC = [10**-12, 10**12] # list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "# rangeGamma = [10**-6, 1] # list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "# rangeCoef0 = [0, 1] # list, float, range of parameter Coef0,eg.[0, 1]"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "    # 检查青蛙是否在可行的搜索空间内\n",
    "    return (rangeC[0] <= Uq[0] <= rangeC[1]) and \\\n",
    "           (rangeGamma[0] <= Uq[1] <= rangeGamma[1])and \\\n",
    "           (Uq[0] >= 0) and \\\n",
    "           (Uq[1] >= 0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:32.733701Z",
     "iopub.execute_input": "2024-04-19T16:19:32.734085Z",
     "iopub.status.idle": "2024-04-19T16:19:32.740960Z",
     "shell.execute_reply.started": "2024-04-19T16:19:32.734056Z",
     "shell.execute_reply": "2024-04-19T16:19:32.739757Z"
    },
    "trusted": true
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_random_frog_rbf(rangeC, rangeGamma):\n",
    "    \"\"\"\n",
    "    Randomly generates a new frog within the feasible space.\n",
    "    \n",
    "    Parameters:\n",
    "    - rangeC: Tuple (min, max) for C parameter.\n",
    "    - rangeGamma: Tuple (min, max) for Gamma parameter.\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "    - Uq: A list containing the randomly generated C, Gamma, and Coef0.\n",
    "    \"\"\"\n",
    "    Uq = [\n",
    "        10**random.uniform(log10(rangeC[0]), log10(rangeC[1])),\n",
    "        10**random.uniform(log10(rangeGamma[0]), log10(rangeGamma[1]))\n",
    "    ]\n",
    "    return Uq\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:34.109064Z",
     "iopub.execute_input": "2024-04-19T16:19:34.109485Z",
     "iopub.status.idle": "2024-04-19T16:19:34.116043Z",
     "shell.execute_reply.started": "2024-04-19T16:19:34.109455Z",
     "shell.execute_reply": "2024-04-19T16:19:34.115007Z"
    },
    "trusted": true
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 正确的rbf"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def SFLA_RBF(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,performance_history00,x_train,y_train):\n",
    "    '''\n",
    "    num_parameter: int, number of parameter to optimize\n",
    "    \n",
    "    num_global: int, the maximum number of global iterations\n",
    "    \n",
    "    num_local: int, the maximum number of local iterations\n",
    "    \n",
    "    m : int, the number of memeplexes\n",
    "    \n",
    "    n : int, the number of frogs in each memeplex\n",
    "    \n",
    "    q : int, the number of frogs in submemeplex\n",
    "    \n",
    "    n1:  number of splits for cross validation for inner loop\n",
    "    \n",
    "    rangeC: list, float, range of parameter C,eg.[10**-2, 10**2]\n",
    "    \n",
    "    rangeGamma: list, float, range of parameter Gamma,eg.[10**-6, 1]\n",
    "    \n",
    "    # rangeCoef0: list, float, range of parameter Coef0,eg.[0, 1]\n",
    "\n",
    "    x_train: feature\n",
    "\n",
    "    y_train: lable\n",
    "\n",
    "    '''\n",
    "\n",
    "    #--- Step 0--Initialize parameters ---#\n",
    "    sizeC = 2\n",
    "    sizeGamma = 2\n",
    "    # sizeCoef0 = 2\n",
    "    improvement_threshold = 10**-4 # 设置一个性能改进的阈值\n",
    "    performance_history = performance_history00 # 用于存储每只青蛙的历史性能和权重\n",
    "    global_flags = False\n",
    "    stop_main_loop = False\n",
    "    # max_step =  [(rangeC[1]-rangeC[0])/sizeC,(rangeGamma[1]-rangeGamma[0])/sizeGamma,(rangeCoef0[1]-rangeCoef0[0])/sizeCoef0]# maximum step size\n",
    "    initial_max_step =  [(rangeC[1]-rangeC[0])/sizeC,(rangeGamma[1]-rangeGamma[0])/sizeGamma]# maximum step size\n",
    "    #--- Step 1--Generate initial population ---#\n",
    "    frogC = 10**random.uniform(log10(rangeC[0]),log10(rangeC[1]),m*n)\n",
    "    frogGamma = 10**random.uniform(log10(rangeGamma[0]),log10(rangeGamma[1]),m*n)\n",
    "    # frogCoef0 = random.uniform(rangeCoef0[0],rangeCoef0[1],m*n)\n",
    "    frog = c_[frogC,frogGamma]\n",
    "\n",
    "    # Compute the performance value for each frog on validation data #\n",
    "    KF = KFold(n_splits=n1,shuffle=True, random_state=920)\n",
    "    f = zeros((m*n,n1))\n",
    "    j = 0\n",
    "    for train_indexcv,test_indexcv in KF.split(x_train):\n",
    "        x_traincv, x_testcv = x_train.iloc[train_indexcv][:], x_train.iloc[test_indexcv][:]\n",
    "        y_traincv, y_testcv = y_train.iloc[train_indexcv][:], y_train.iloc[test_indexcv][:]\n",
    "        for i in range(m*n):\n",
    "            f[i,j] = SFLA_SVM(x_traincv, y_traincv,x_testcv, y_testcv,kernel,frog[i,0],frog[i,1])\n",
    "        j+=1\n",
    "    f = f.mean(axis=1)\n",
    "    f_parameter = c_[f,frog]\n",
    "\n",
    "    #--- Step 2--Rank frogs ---#\n",
    "    f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "\n",
    "    #######--- Global search start---######\n",
    "    i_global = 0\n",
    "    flag = 0\n",
    "    fBest_iteration = f_parameter[0,0]\n",
    "    weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "    while i_global < num_global:\n",
    "        # Dynamically adjust the maximum step size based on the iteration number\n",
    "        decay_factor = 0.89  # This factor determines how much the step size is reduced\n",
    "        max_step = [x * (decay_factor ** i_global) for x in initial_max_step]\n",
    "        frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "        #--- Step 3--Partition frogs into memeplexes ---#\n",
    "        memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma,Coef0] ]\n",
    "        for i in range(m):\n",
    "            memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "\n",
    "       #######--- Global search start---######\n",
    "        i_global = 0\n",
    "        flag = 0\n",
    "        fBest_iteration = f_parameter[0,0]\n",
    "        iteration = 1              # 当前迭代次数高斯\n",
    "        max_iterations = 10        # 最大迭代次数高斯\n",
    "        iteration_sa = 1\n",
    "        \n",
    "        # 初始化温度参数\n",
    "        initial_temp = 0.00004342944819032519\n",
    "        cooling_rate = 1.175  # 温度增长率\n",
    "        T = initial_temp  # 当前温度\n",
    "        global_flags = False\n",
    "        stop_main_loop = False\n",
    "        markf = 0\n",
    "        weights = [2*(n+1-j)/(n*(n+1)) for j in range(1,n+1)] # weights of ranked frogs in each memeplex\n",
    "        while i_global < num_global:\n",
    "            # Dynamically adjust the maximum step size based on the iteration number\n",
    "            decay_factor = 0.89  # This factor determines how much the step size is reduced\n",
    "            max_step = [x * (decay_factor ** i_global) for x in initial_max_step]\n",
    "            frog_gb = f_parameter[0,0] # mark the global best frog      \n",
    "            # Step 3: Partition frogs into memeplexes\n",
    "            memeplexes = zeros((m,n,num_parameter+1)) # [memeplexes, frog in memeplex,[f,C,Gamma,Coef0] ]\n",
    "            for i in range(m):\n",
    "                memeplexes[i] = f_parameter[linspace(i,m*n+i,num=n,endpoint=False,dtype=int)]\n",
    "            #######--- Local search start---######\n",
    "            # Step 4: Memetic evolution within each memeplex\n",
    "            im = 0 # the number of memeplexes that have been optimized\n",
    "            global_flags = False\n",
    "            stop_main_loop = False\n",
    "            markf = 0 # 这个就是标记是否在子复合体中找到了有效改进解，如果这个标记是1，说明没有找到\n",
    "            while im < m:\n",
    "                global_flags = False\n",
    "                stop_main_loop = False\n",
    "                i_local = 0 # counts the number of local evolutionary steps in each memeplex\n",
    "                while i_local < num_local:\n",
    "                    # Construct a submemeplex\n",
    "                    memeplex_indices = range(im * n, (im + 1) * n)\n",
    "                    if not all(performance_history[memeplex_indices, 1] == 0):\n",
    "                        rValue = random.random(q)\n",
    "                        memeplex_weights = performance_history[memeplex_indices, 1]\n",
    "                        random_indices = random.choice(memeplex_indices, size=q, p=memeplex_weights/sum(memeplex_weights), replace=False)\n",
    "                        selected_weights = performance_history[random_indices, 1]\n",
    "                        rValue *= selected_weights\n",
    "                        subindex = sort(argsort(rValue)[::-1][0:q])\n",
    "                    else:\n",
    "                        rValue = random.random(n)*weights \n",
    "                        subindex = sort(argsort(rValue)[::-1][0:q]) # index of selected frogs in memeplex \n",
    "                    submemeplex = memeplexes[im][subindex] # form submemeplex\n",
    "                    # Improve the worst frog's position using Simulated Annealing\n",
    "                    Pb = submemeplex[0]  # mark the best frog in submemeplex\n",
    "                    Pw = submemeplex[q-1]  # mark the worst frog in memeplex\n",
    "                    S = (Pb - Pw)[1:] * (Pb - Pw)[0]\n",
    "                    Uq = Pw[1:] + S\n",
    "                    # Check feasible space and the performance\n",
    "                    if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                        fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                        if fq < Pw[0]:\n",
    "                            # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                            # 改进为使用结合模拟退火算法的高斯插值方法混合当前青蛙和全局最佳青蛙的参数，而不是完全随机生成\n",
    "                            # 注意这里退火算法我改了，评价指标改成一个单增的函数，就表示如果最坏青蛙向最好青蛙学习之后，如果性能下降了，但下降的越少的学习结果越容易被接受\n",
    "                            while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                                    fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                                    if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                        while iteration_sa < max_iterations + 1:\n",
    "                                            if random.rand() > exp(-(Pw[0] - fq) / T):#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右,\n",
    "                                                #如果相差在0.0015，那么最大接受概率约为0.5023096165445047，0.1~0.6318989908213715，这里就是为了带来随机性，增加鲁棒性\n",
    "                                                T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                iteration_sa += 1\n",
    "                                            else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                top_main_loop = True\n",
    "                                                global_flags = True\n",
    "                                                iteration_sa = 1\n",
    "                                                break\n",
    "                                        T = initial_temp #记得再次初始化T，不然T乘直接乘爆炸了\n",
    "                                        iteration_sa = 1\n",
    "                                iteration += 1\n",
    "                            if iteration == max_iterations + 1:\n",
    "                                markf = 1 #这就说明上面的没有找到局部改进解\n",
    "                            stop_main_loop = False    \n",
    "                            iteration = 1\n",
    "                        elif markf == 1: # if local parameter has not been improved then we go global for searching\n",
    "                            markf = 0\n",
    "                             # if searching has no result.get a new direction from the global best frog randomly\n",
    "                            S = random.random(num_parameter) * (frog_gb - Pw)[1:]\n",
    "                            for i in range(num_parameter):\n",
    "                                if S[i] > 0:\n",
    "                                    S[i] = min(S[i], max_step[i])\n",
    "                                else:\n",
    "                                    S[i] = min(S[i], -max_step[i])\n",
    "                            Uq = Pw[1:] + S\n",
    "                            if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                                if fq < Pw[0]:\n",
    "                                # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                                    while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                        Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                        if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                                            if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                                while iteration_sa < max_iterations + 1:\n",
    "                                                    if random.rand() > exp(-(Pw[0] - fq) / T) :#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右\n",
    "                                                        T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                        iteration_sa += 1\n",
    "                                                    else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                        top_main_loop = True\n",
    "                                                        global_flags = True\n",
    "                                                        iteration_sa = 1\n",
    "                                                        break\n",
    "                                                T = initial_temp #记得再次初始化T\n",
    "                                                iteration_sa = 1\n",
    "                                        iteration += 1\n",
    "                                    stop_main_loop = False\n",
    "                                    iteration = 1\n",
    "                            else:# 注意这里还是在前提，是在局部学习和全局学习都没有提升的前提下，这里还有一个前提是在局部学习是在可行界内的\n",
    "                                # If both local and global 's performances are not improved and new solution is not accepted based on annealing probability\n",
    "                                # Randomly generate a legal frog within the submemeplex\n",
    "                                Uq = generate_random_frog_rbf(rangeC, rangeGamma)\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                    else: # 如果局部学习直接不在可行解内了\n",
    "                        # If the worst frog 1 is beyond the search space, get a new direction from the global best frog for search\n",
    "                        S = random.random(num_parameter) * (frog_gb - Pw)[1:]\n",
    "                        for i in range(num_parameter):\n",
    "                            if S[i] > 0:\n",
    "                                S[i] = min(S[i], max_step[i])\n",
    "                            else:\n",
    "                                S[i] = min(S[i], -max_step[i])\n",
    "                        Uq = Pw[1:] + S\n",
    "                        if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                            if fq < Pw[0]:\n",
    "                            # If performance is not improved and we go the adaptative_gaussian_perturbation and annealing probability\n",
    "                                while iteration < max_iterations + 1 and not stop_main_loop:\n",
    "                                    Uq = adaptative_gaussian_perturbation(Pw, frog_gb, iteration, max_iterations)\n",
    "                                    if check_within_bounds_rbf(Uq, rangeC, rangeGamma):\n",
    "                                        fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                                        if fq < Pw[0]:#if performance is still not improved using SA algorithm 看看他们的差距是不是足够小\n",
    "                                            while iteration_sa < max_iterations + 1:\n",
    "                                                if random.rand() > exp(-(Pw[0] - fq) / T) :#这个值是接受概率，如果和原始worst相差为0.002，那么逆退火算法的最大接受概率在0.4左右\n",
    "                                                    T *= cooling_rate #如果不被接受，那么降低温度\n",
    "                                                    iteration_sa += 1\n",
    "                                                else:#一但有被接受的值，停止降温退出模拟退火算法\n",
    "                                                    top_main_loop = True\n",
    "                                                    global_flags = True\n",
    "                                                    iteration_sa = 1\n",
    "                                                    break\n",
    "                                            T = initial_temp #记得再次初始化T\n",
    "                                            iteration_sa = 1\n",
    "                                    iteration += 1\n",
    "                                stop_main_loop = False\n",
    "                                iteration = 1\n",
    "                            else:\n",
    "                                # if global learning is not improved Randomly generate a legal frog within the submemeplex\n",
    "                                Uq = generate_random_frog_rbf(rangeC, rangeGamma)\n",
    "                                fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "                        # if the space of the global learning is not feasible  Randomly generate a legal frog within the submemeplex\n",
    "                        else:\n",
    "                            Uq = generate_random_frog_rbf(rangeC, rangeGamma)\n",
    "                            fq = SFLA_SVM_CV(x_train, y_train, n1, kernel, Uq[0], Uq[1])\n",
    "#                     # Upgrade the memeplex\n",
    "#                     memeplexes[im][subindex[q-1]] = r_[fq, Uq]\n",
    "#                     memeplexes[im] = memeplexes[im][argsort(memeplexes[im][:,0])[::-1]]\n",
    "                    if fq > Pw[0] : # If there is performance improvement\n",
    "                        memeplexes[im][subindex[q-1]] = r_[fq,Uq]\n",
    "                        # Update the frog's historical performance and weight\n",
    "                        performance_history[subindex[q-1], 0] = fq\n",
    "                        performance_history[subindex[q-1], 1] += improvement_threshold # Increase weight\n",
    "                    elif global_flags == True : # If there is SA ACCECPT which means  the worst frog is closed to the best Within the tolerable performance degradation range\n",
    "                        # Update the frog's historical performance and weight\n",
    "                        performance_history[subindex[q-1], 0] = fq\n",
    "                        performance_history[subindex[q-1], 1] += improvement_threshold # Increase weight\n",
    "                        global_flags = False\n",
    "                    else:\n",
    "                        # If there is no performance improvement,and no SA ACCECPT, reduce the weight\n",
    "                        performance_history[subindex[q-1], 1] = max(performance_history[subindex[q-1], 1] - improvement_threshold, 0.1) # Ensure weight does not become zero\n",
    "                        #  By setting a minimum weight as 0.1, we ensure that every frog still has a chance to be selected, \n",
    "                        # but those with better performance have a higher probability.\n",
    "                    i_local += 1\n",
    "                im += 1\n",
    "            #######--- Local search end---######\n",
    "            # Step 5: Shuffle memeplexes\n",
    "            f_parameter = memeplexes.reshape(m*n,num_parameter+1)\n",
    "            f_parameter = f_parameter[argsort(f_parameter[:,0])[::-1]]\n",
    "            i_global += 1\n",
    "            # Step 6: Check convergence\n",
    "            if f_parameter[0,0] > 0.99:\n",
    "                print('The program was terminated because it reached the optimization goal with f = %.3f' %f_parameter[0,0])\n",
    "                break\n",
    "            if abs(frog_gb - f_parameter[0,0]) < 10**-4:\n",
    "                flag += 1\n",
    "            if flag > 5:\n",
    "                break\n",
    "            fBest_iteration = r_[fBest_iteration, f_parameter[0,0]]\n",
    "        #######--- Global search end---######\n",
    "        return (f_parameter[0], fBest_iteration)\n",
    "\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:36.033230Z",
     "iopub.execute_input": "2024-04-19T16:19:36.033627Z",
     "iopub.status.idle": "2024-04-19T16:19:36.097466Z",
     "shell.execute_reply.started": "2024-04-19T16:19:36.033597Z",
     "shell.execute_reply": "2024-04-19T16:19:36.096491Z"
    },
    "trusted": true
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_vertical_line(x,y,color,marker):\n",
    "    fig = plt.figure()\n",
    "    for i in range(size(x)):\n",
    "        x0 = [x[i], x[i]]\n",
    "        y0 = [min(y)-0.005, y[i]]\n",
    "        plt.plot(x0,y0,color=color)\n",
    "    plt.scatter(x, y, color=color, alpha=0.5, marker=marker)\n",
    "    return fig"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:39.087493Z",
     "iopub.execute_input": "2024-04-19T16:19:39.087901Z",
     "iopub.status.idle": "2024-04-19T16:19:39.095254Z",
     "shell.execute_reply.started": "2024-04-19T16:19:39.087870Z",
     "shell.execute_reply": "2024-04-19T16:19:39.093874Z"
    },
    "trusted": true
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from joblib import Parallel, delayed\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix as cm, accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "def train_and_evaluate(train_index, test_index, x, y, n1, kernel, rangeC, rangeGamma, num_parameter, num_global, num_local, m, n, q, performance_history):\n",
    "#     # 选取训练集和测试集\n",
    "#     x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "#     y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "#     # 处理NaN值\n",
    "#     x_train.fillna(0, inplace=True)\n",
    "#     x_test.fillna(0, inplace=True)\n",
    "    #---  Seperate traing set and test set ---#\n",
    "    y_score = []\n",
    "    y_test = []\n",
    "    x_train, x_test = x.iloc[train_index][:], x.iloc[test_index][:]\n",
    "    y_train = y.iloc[train_index][:]\n",
    "        \n",
    "    #---  Fill NaN age ---#\n",
    "    x_train[isnan(x_train)] = 0\n",
    "    x_test[isnan(x_test)] = 0    \n",
    "        \n",
    "    ##---  optimize SVM with SFLA---##\n",
    "    x_train = pd.DataFrame(x_train) \n",
    "    y_train = pd.Series(y_train)\n",
    "    \n",
    "    if kernel == 'poly':\n",
    "        f_parameter,fBest_iteration = SFLA_POLY(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeDegree,rangeCoef0,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],degree=f_parameter[3],coef0=f_parameter[4],probability=True,random_state=920)\n",
    "            \n",
    "        \n",
    "    if kernel == 'rbf':\n",
    "        f_parameter,fBest_iteration = SFLA_RBF(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,performance_history,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],probability=True,random_state=920)\n",
    "        \n",
    "    if kernel == 'linear':\n",
    "        f_parameter,fBest_iteration = SFLA_LINEAR(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,x_train,y_train)\n",
    "         # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "        \n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],probability=True,random_state=920)\n",
    "        \n",
    "    if kernel == 'sigmoid':\n",
    "        f_parameter,fBest_iteration = SFLA_SIGMOID(num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma,rangeCoef0,performance_history,x_train,y_train)\n",
    "        # f_parameter: list, [bestAUC,bestC,bestGamma,bestDegree,bestCoef0]   fBest_iteration: bestAUC in each iteration\n",
    "    \n",
    "        ##---  creat and train the model ---##\n",
    "        clf = svm.SVC(kernel=kernel,C=f_parameter[1],gamma=f_parameter[2],coef0=f_parameter[3],probability=True,random_state=920)\n",
    "\n",
    "    # 输出参数\n",
    "    print(f_parameter)\n",
    "    \n",
    "    # 创建并训练SVM模型\n",
    "    # clf = svm.SVC(kernel=kernel, C=f_parameter[1], gamma=f_parameter[2], coef0=f_parameter[3], probability=True, random_state=920)\n",
    "    clf.fit(x_train, y_train)\n",
    "    # Make predictions\n",
    "    y_score = clf.predict_proba(x_test)[:, 1]\n",
    "    y_test = y.iloc[test_index].tolist()\n",
    "    # Check if y_test and y_score have the same length\n",
    "    if len(y_test) != len(y_score):\n",
    "        raise ValueError(f\"Inconsistent number of samples: y_test has {len(y_test)} elements, y_score has {len(y_score)} elements\")\n",
    "\n",
    "    # Compute AUC\n",
    "    fpr, tpr, threshold = roc_curve(y_test, y_score, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('AUC:', roc_auc)\n",
    "    \n",
    "    return y_score, y_test, roc_auc, clf\n",
    "    \n",
    "\n",
    "# 主函数\n",
    "def OptimizeSVM_SFLA_CV(x, y, n_splits, num_parameter, num_global, num_local, m, n, q, n1, kernel, rangeC, rangeGamma=False, rangeDegree=False):\n",
    "    performance_history = np.zeros((m*n, 2)) + 1.0\n",
    "    KF = KFold(n_splits=n_splits, shuffle=True, random_state=random.randint(1, 1000))\n",
    "    y_score = []\n",
    "    y_test = []\n",
    "    # 使用joblib并行处理\n",
    "    results = Parallel(n_jobs=-1, verbose=10)(delayed(train_and_evaluate)(\n",
    "        train_index, test_index, x, y, n1, kernel, rangeC, rangeGamma, num_parameter, num_global, num_local, m, n, q, performance_history\n",
    "    ) for train_index, test_index in KF.split(x))\n",
    "\n",
    "    # 合并结果\n",
    "    y_scores = [score for result in results for score in result[0]]\n",
    "    y_tests = [y_test for result in results for y_test in result[1]]\n",
    "    roc_aucs = [result[2] for result in results]\n",
    "    clf = [result[3] for result in results]\n",
    "    \n",
    "\n",
    "    \n",
    "    # 输出整体AUC\n",
    "    fpr, tpr, threshold = roc_curve(y_tests, y_scores, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # print('Overall AUC:', roc_auc)\n",
    "\n",
    "    # 计算其他性能指标\n",
    "    y_pred = [round(score) for score in y_scores]\n",
    "    print(cm(y_tests, y_pred))\n",
    "    a = accuracy_score(y_tests, y_pred)\n",
    "    p = precision_score(y_tests, y_pred)\n",
    "    r = recall_score(y_tests, y_pred)\n",
    "    f1score = f1_score(y_tests, y_pred)\n",
    "    print(f'Accuracy: {a:.2f}\\nPrecision: {p:.2f}\\nRecall: {r:.2f}\\nF1 Score: {f1score:.2f}\\nAUC: {roc_auc:.4f}\\n')\n",
    "\n",
    "    return clf, a, p, r, f1score, roc_auc, y_pred, y_scores, fpr, tpr\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T16:19:40.721095Z",
     "iopub.execute_input": "2024-04-19T16:19:40.721480Z",
     "iopub.status.idle": "2024-04-19T16:19:40.749586Z",
     "shell.execute_reply.started": "2024-04-19T16:19:40.721448Z",
     "shell.execute_reply": "2024-04-19T16:19:40.748512Z"
    },
    "trusted": true
   },
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "x_df = pd.DataFrame(x)\n",
    "y_s = pd.Series(y.ravel()) \n",
    "start = time.process_time()\n",
    "n_splits = 10 # 减少外循环的分割数\n",
    "num_parameter = 2\n",
    "num_global = 15 # 减少全局迭代的次数\n",
    "num_local = 10 # 减少局部迭代的次数\n",
    "m = 4 # 减少记忆复合体的数量\n",
    "n = 8 # 减少每个记忆复合体中的青蛙数量\n",
    "q = 5 # 减少子记忆复合体中的青蛙数量\n",
    "n1 = 10 # 减少内循环的分割数\n",
    "kernel = 'rbf'\n",
    "rangeC = [0.00001, 10000] # 缩小参数C的范围\n",
    "rangeGamma = [0.00001, 1] # 缩小参数Gamma的范围\n",
    "clf, a, p, r, f1score,roc_auc, y_pred,y_score,fpr, tpr = OptimizeSVM_SFLA_CV(x_df,y_s,n_splits,num_parameter,num_global,num_local,m,n,q,n1,kernel,rangeC,rangeGamma)\n",
    "end = time.process_time()\n",
    "print('OptimizeSVM_SFLA_CV algorithm takes '+str(end - start)+'seconds.\\n') "
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T17:14:53.203876Z",
     "iopub.execute_input": "2024-04-19T17:14:53.204289Z",
     "iopub.status.idle": "2024-04-19T18:38:26.601316Z",
     "shell.execute_reply.started": "2024-04-19T17:14:53.204255Z",
     "shell.execute_reply": "2024-04-19T18:38:26.600035Z"
    },
    "trusted": true
   },
   "execution_count": 25,
   "outputs": [
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_33/4184709805.py:3: FutureWarning: Series.ravel is deprecated. The underlying array is already 1D, so ravel is not necessary.  Use `to_numpy()` for conversion to a numpy array instead.\n  y_s = pd.Series(y.ravel())\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed: 55.9min remaining: 55.9min\n[Parallel(n_jobs=-1)]: Done   7 out of  10 | elapsed: 69.9min remaining: 30.0min\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "[9.46279769e-01 5.19474123e+03 1.61736418e-05]\nAUC: 0.9236111111111113\n[ 0.93794814 10.64364407  0.01435079]\nAUC: 0.9545454545454546\n[0.94271282 3.65272996 0.2138253 ]\nAUC: 0.8826086956521739\n[9.40053020e-01 1.00386741e+03 5.07804659e-04]\nAUC: 0.8935185185185185\n[9.33440518e-01 2.86814249e+03 7.33346324e-05]\nAUC: 0.9583333333333334\n[9.40875681e-01 3.45220433e+01 7.12835315e-03]\nAUC: 0.9004524886877828\n[0.94198641 1.576793   0.01619831]\nAUC: 0.9130434782608696\n[ 0.93641386 12.69866767  0.02452595]\nAUC: 0.9533333333333334\n[9.37642098e-01 1.03266385e+02 1.47430904e-03]\nAUC: 0.9749999999999999\n[0.94409426 0.97485275 0.03727514]\nAUC: 0.931350114416476\n[[198  17]\n [ 37 171]]\nAccuracy: 0.87\nPrecision: 0.91\nRecall: 0.82\nF1 Score: 0.86\nAUC: 0.9319\n\nOptimizeSVM_SFLA_CV algorithm takes 21.954937358seconds.\n\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 83.6min finished\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def plot_roc(fpr, tpr):\n",
    "    # ROC AUC\n",
    "    # fpr, tpr, thresholds = metrics.roc_curve(validY, validProb, pos_label=1)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "    print(\"ROC_AUC :\", roc_auc)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.patch.set_facecolor('#e8e8f8')\n",
    "    plt.plot(fpr, tpr, 'k-', lw=2, color='#7777cb')\n",
    "    plt.title('AUC={:.4f}'.format(roc_auc))\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    plt.gca().set_facecolor('#e8e8f8')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "print(plot_roc(fpr, tpr))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-19T18:42:57.996858Z",
     "iopub.execute_input": "2024-04-19T18:42:57.997253Z",
     "iopub.status.idle": "2024-04-19T18:42:58.281711Z",
     "shell.execute_reply.started": "2024-04-19T18:42:57.997225Z",
     "shell.execute_reply": "2024-04-19T18:42:58.280613Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "text": "ROC_AUC : 0.9319320214669051\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_33/3174306646.py:10: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k-\" (-> color='k'). The keyword argument will take precedence.\n  plt.plot(fpr, tpr, 'k-', lw=2, color='#7777cb')\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "None\n[0.94463054 3.65737241 0.04487479]\nAUC: 0.8896103896103895\n[0.938405   5.07993108 0.05246592]\nAUC: 0.9670588235294117\n[0.93465116 0.70881325 0.05516302]\nAUC: 0.9294117647058824\n[0.93747166 0.76091721 0.08422983]\nAUC: 0.9069264069264068\n[0.93578812 4.95440892 0.04581721]\nAUC: 0.9105882352941177\n[0.94318111 0.60741528 0.05935901]\nAUC: 0.9927884615384615\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
